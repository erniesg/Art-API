{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b712517f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T08:35:49.029067Z",
     "start_time": "2023-03-07T08:35:48.182511Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d621eb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T08:18:46.970350Z",
     "start_time": "2023-03-07T08:18:44.510379Z"
    }
   },
   "outputs": [],
   "source": [
    "df=pd.read_excel(\"../raw_data/csv/data_csv_Artplus 220808 List of Gallery works.xlsx\", dtype='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6950a3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T08:18:47.001699Z",
     "start_time": "2023-03-07T08:18:46.973123Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Record ID</th>\n",
       "      <th>Accession No.</th>\n",
       "      <th>Artist/Maker</th>\n",
       "      <th>Title</th>\n",
       "      <th>Image</th>\n",
       "      <th>Dating</th>\n",
       "      <th>Medium</th>\n",
       "      <th>Dimensions</th>\n",
       "      <th>Geo. Reference</th>\n",
       "      <th>Credit Line</th>\n",
       "      <th>Rights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100012362</td>\n",
       "      <td>2009-02997</td>\n",
       "      <td>Lim Cheng Hoe  (1912–1979)</td>\n",
       "      <td>Fishing Village at Kukup</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1963</td>\n",
       "      <td>Watercolour on paper</td>\n",
       "      <td>Mount Measurement: 67.1 x 87.1 cm\\nObject Dime...</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Collection of National Gallery Singapore</td>\n",
       "      <td>CF - copyright documents received, full copyri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100012363</td>\n",
       "      <td>P-0927</td>\n",
       "      <td>Lim Cheng Hoe  (1912–1979)</td>\n",
       "      <td>Fort Canning Gateway</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1959</td>\n",
       "      <td>Watercolour on paper</td>\n",
       "      <td>Object Dimensions: 31.0 x 40.0 cm</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Collection of National Gallery Singapore</td>\n",
       "      <td>CF - copyright documents received, full copyri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100012364</td>\n",
       "      <td>P-0450</td>\n",
       "      <td>Lim Cheng Hoe  (1912–1979)</td>\n",
       "      <td>Singapore River</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1962</td>\n",
       "      <td>Watercolour on paper</td>\n",
       "      <td>Object Dimensions: 37.8 x 50.5 cm</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Collection of National Gallery Singapore</td>\n",
       "      <td>CF - copyright documents received, full copyri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100012365</td>\n",
       "      <td>P-0447</td>\n",
       "      <td>Lim Cheng Hoe  (1912–1979)</td>\n",
       "      <td>Portrait of T. Y. Choy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1965-1970</td>\n",
       "      <td>Watercolour on paper</td>\n",
       "      <td>Object Dimensions: 53.0 x 32.0 cm</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Gift of Michael Lim Hock Ann. Collection of Na...</td>\n",
       "      <td>CF - copyright documents received, full copyri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100012366</td>\n",
       "      <td>2009-01799</td>\n",
       "      <td>Latiff Mohidin (1941–)</td>\n",
       "      <td>Aku</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1958</td>\n",
       "      <td>Oil on board</td>\n",
       "      <td>Frame measure: 43.0 x 33.0 x 2.5 cm\\nObject Di...</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Collection of National Gallery Singapore</td>\n",
       "      <td>CF - copyright documents received, full copyri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10256</th>\n",
       "      <td>100053413</td>\n",
       "      <td>2021-01003</td>\n",
       "      <td>Phạm Thanh Tâm (1932–2019)</td>\n",
       "      <td>Not titled (75mm cannon at Dien Bien Phu)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1954</td>\n",
       "      <td>Graphite pencil on machine made paper</td>\n",
       "      <td>Image measure: 16.5 x 12.0 cm\\nObject measure:...</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>Collection of National Gallery Singapore</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10257</th>\n",
       "      <td>100053414</td>\n",
       "      <td>2021-01004</td>\n",
       "      <td>Phạm Thanh Tâm (1932–2019)</td>\n",
       "      <td>Saigon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1975</td>\n",
       "      <td>Ink on machine made paper</td>\n",
       "      <td>Image measure: 23.3 x 18.0 cm\\nObject measure:...</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>Collection of National Gallery Singapore</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10258</th>\n",
       "      <td>100053415</td>\n",
       "      <td>2021-01005</td>\n",
       "      <td>Phạm Thanh Tâm (1932–2019)</td>\n",
       "      <td>Saigon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1975</td>\n",
       "      <td>Ink on machine made paper</td>\n",
       "      <td>Image measure: 11.9 x 18.0 cm\\nObject measure:...</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>Collection of National Gallery Singapore</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10259</th>\n",
       "      <td>100053416</td>\n",
       "      <td>2021-01006</td>\n",
       "      <td>Phạm Thanh Tâm (1932–2019)</td>\n",
       "      <td>Not titled (Rex Hotel, Saigon)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1975</td>\n",
       "      <td>Ink on machine made paper</td>\n",
       "      <td>Image measure: 7.6 x 11.6 cm\\nObject measure: ...</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>Collection of National Gallery Singapore</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10260</th>\n",
       "      <td>100053417</td>\n",
       "      <td>2021-01007</td>\n",
       "      <td>Phạm Thanh Tâm (1932–2019)</td>\n",
       "      <td>Phố Gia Long - Sài Gòn ngày giải phóng (Gia Lo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1975</td>\n",
       "      <td>Ink on machine made paper</td>\n",
       "      <td>Image measure: 17.2 x 12.2 cm\\nObject measure:...</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>Collection of National Gallery Singapore</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10261 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Record ID Accession No.                Artist/Maker  \\\n",
       "0      100012362    2009-02997  Lim Cheng Hoe  (1912–1979)   \n",
       "1      100012363        P-0927  Lim Cheng Hoe  (1912–1979)   \n",
       "2      100012364        P-0450  Lim Cheng Hoe  (1912–1979)   \n",
       "3      100012365        P-0447  Lim Cheng Hoe  (1912–1979)   \n",
       "4      100012366    2009-01799      Latiff Mohidin (1941–)   \n",
       "...          ...           ...                         ...   \n",
       "10256  100053413    2021-01003  Phạm Thanh Tâm (1932–2019)   \n",
       "10257  100053414    2021-01004  Phạm Thanh Tâm (1932–2019)   \n",
       "10258  100053415    2021-01005  Phạm Thanh Tâm (1932–2019)   \n",
       "10259  100053416    2021-01006  Phạm Thanh Tâm (1932–2019)   \n",
       "10260  100053417    2021-01007  Phạm Thanh Tâm (1932–2019)   \n",
       "\n",
       "                                                   Title Image     Dating  \\\n",
       "0                               Fishing Village at Kukup   NaN       1963   \n",
       "1                                   Fort Canning Gateway   NaN       1959   \n",
       "2                                        Singapore River   NaN       1962   \n",
       "3                                 Portrait of T. Y. Choy   NaN  1965-1970   \n",
       "4                                                    Aku   NaN       1958   \n",
       "...                                                  ...   ...        ...   \n",
       "10256          Not titled (75mm cannon at Dien Bien Phu)   NaN       1954   \n",
       "10257                                             Saigon   NaN       1975   \n",
       "10258                                             Saigon   NaN       1975   \n",
       "10259                     Not titled (Rex Hotel, Saigon)   NaN       1975   \n",
       "10260  Phố Gia Long - Sài Gòn ngày giải phóng (Gia Lo...   NaN       1975   \n",
       "\n",
       "                                      Medium  \\\n",
       "0                       Watercolour on paper   \n",
       "1                       Watercolour on paper   \n",
       "2                       Watercolour on paper   \n",
       "3                       Watercolour on paper   \n",
       "4                               Oil on board   \n",
       "...                                      ...   \n",
       "10256  Graphite pencil on machine made paper   \n",
       "10257              Ink on machine made paper   \n",
       "10258              Ink on machine made paper   \n",
       "10259              Ink on machine made paper   \n",
       "10260              Ink on machine made paper   \n",
       "\n",
       "                                              Dimensions Geo. Reference  \\\n",
       "0      Mount Measurement: 67.1 x 87.1 cm\\nObject Dime...      Singapore   \n",
       "1                      Object Dimensions: 31.0 x 40.0 cm      Singapore   \n",
       "2                      Object Dimensions: 37.8 x 50.5 cm      Singapore   \n",
       "3                      Object Dimensions: 53.0 x 32.0 cm      Singapore   \n",
       "4      Frame measure: 43.0 x 33.0 x 2.5 cm\\nObject Di...      Singapore   \n",
       "...                                                  ...            ...   \n",
       "10256  Image measure: 16.5 x 12.0 cm\\nObject measure:...        Vietnam   \n",
       "10257  Image measure: 23.3 x 18.0 cm\\nObject measure:...        Vietnam   \n",
       "10258  Image measure: 11.9 x 18.0 cm\\nObject measure:...        Vietnam   \n",
       "10259  Image measure: 7.6 x 11.6 cm\\nObject measure: ...        Vietnam   \n",
       "10260  Image measure: 17.2 x 12.2 cm\\nObject measure:...        Vietnam   \n",
       "\n",
       "                                             Credit Line  \\\n",
       "0               Collection of National Gallery Singapore   \n",
       "1               Collection of National Gallery Singapore   \n",
       "2               Collection of National Gallery Singapore   \n",
       "3      Gift of Michael Lim Hock Ann. Collection of Na...   \n",
       "4               Collection of National Gallery Singapore   \n",
       "...                                                  ...   \n",
       "10256           Collection of National Gallery Singapore   \n",
       "10257           Collection of National Gallery Singapore   \n",
       "10258           Collection of National Gallery Singapore   \n",
       "10259           Collection of National Gallery Singapore   \n",
       "10260           Collection of National Gallery Singapore   \n",
       "\n",
       "                                                  Rights  \n",
       "0      CF - copyright documents received, full copyri...  \n",
       "1      CF - copyright documents received, full copyri...  \n",
       "2      CF - copyright documents received, full copyri...  \n",
       "3      CF - copyright documents received, full copyri...  \n",
       "4      CF - copyright documents received, full copyri...  \n",
       "...                                                  ...  \n",
       "10256                                                NaN  \n",
       "10257                                                NaN  \n",
       "10258                                                NaN  \n",
       "10259                                                NaN  \n",
       "10260                                                NaN  \n",
       "\n",
       "[10261 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a68c8f57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T08:18:50.355648Z",
     "start_time": "2023-03-07T08:18:50.348353Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Record ID', 'Accession No.', 'Artist/Maker', 'Title', 'Image',\n",
       "       'Dating', 'Medium', 'Dimensions', 'Geo. Reference', 'Credit Line',\n",
       "       'Rights'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a1781e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T08:19:12.759372Z",
     "start_time": "2023-03-07T08:19:12.635674Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"ngs_artplus.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1ef4d3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T08:20:33.849507Z",
     "start_time": "2023-03-07T08:20:33.781273Z"
    }
   },
   "outputs": [],
   "source": [
    "df2=pd.read_csv(\"../raw_data/csv/ngs_artplus.csv\", dtype='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "675e742d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T08:20:44.686897Z",
     "start_time": "2023-03-07T08:20:44.682296Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Record ID', 'Accession No.', 'Artist/Maker', 'Title',\n",
       "       'Image', 'Dating', 'Medium', 'Dimensions', 'Geo. Reference',\n",
       "       'Credit Line', 'Rights'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d323e50c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T08:38:46.389702Z",
     "start_time": "2023-03-07T08:38:46.196584Z"
    }
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"../raw_data/csv/data_csv_df_10K_nhb_all.csv\", dtype='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e1038f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T08:39:19.866812Z",
     "start_time": "2023-03-07T08:39:05.579910Z"
    }
   },
   "outputs": [],
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "profile = ProfileReport(df, title=\"Pandas Profiling Report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fce4c6a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T08:59:47.963438Z",
     "start_time": "2023-03-07T08:39:31.702938Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40f4d30a6fb94dbc855bbd1758792bb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/scipy/stats/_stats_py.py:110: RuntimeWarning: The input array could not be properly checked for nan values. nan values will be ignored.\n",
      "  warnings.warn(\"The input array could not be properly \"\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/scipy/stats/_stats_py.py:110: RuntimeWarning: The input array could not be properly checked for nan values. nan values will be ignored.\n",
      "  warnings.warn(\"The input array could not be properly \"\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/correlations.py:67: UserWarning: There was an attempt to calculate the auto correlation, but this failed.\n",
      "To hide this warning, disable the calculation\n",
      "(using `df.profile_report(correlations={\"auto\": {\"calculate\": False}})`\n",
      "If this is problematic for your use case, please report this as an issue:\n",
      "https://github.com/ydataai/ydata-profiling/issues\n",
      "(include the error message: 'No data; `observed` has size 0.')\n",
      "  warnings.warn(\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "/Users/enjiaochen/.pyenv/versions/lewagon/lib/python3.8/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0f31aedfe464731bfc9bd282c28e46f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render widgets:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96561bc6b4ba449fa3f19f67f2f43d60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Tab(children=(Tab(children=(GridBox(children=(VBox(children=(GridspecLayout(children=(HTML(valu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "profile.to_widgets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6533deba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T07:12:40.126510Z",
     "start_time": "2023-02-14T07:12:40.104582Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>documents_0_id</th>\n",
       "      <th>documents_0_title</th>\n",
       "      <th>documents_0_source</th>\n",
       "      <th>documents_0_path</th>\n",
       "      <th>documents_0_content</th>\n",
       "      <th>documents_0_lastModifiedDate</th>\n",
       "      <th>documents_0_metadata_rootsUuid</th>\n",
       "      <th>documents_0_metadata_date_period</th>\n",
       "      <th>documents_0_metadata_collection_of</th>\n",
       "      <th>...</th>\n",
       "      <th>documents_0_tags_subject_29</th>\n",
       "      <th>documents_0_tags_subject_30</th>\n",
       "      <th>documents_0_tags_subject_31</th>\n",
       "      <th>documents_0_tags_subject_32</th>\n",
       "      <th>documents_0_tags_subject_33</th>\n",
       "      <th>documents_0_tags_geobuildings_5</th>\n",
       "      <th>documents_0_tags_geobuildings_6</th>\n",
       "      <th>documents_0_tags_geobuildings_7</th>\n",
       "      <th>documents_0_metadata_scale_type</th>\n",
       "      <th>documents_0_metadata_material_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>47E60712-DB30-42AE-BFDF-3C4918065A91</td>\n",
       "      <td>Handbill for the Cantonese movie, ‘Peach Bloss...</td>\n",
       "      <td>roots_collections</td>\n",
       "      <td>https://www.roots.gov.sg/Collection-Landing/li...</td>\n",
       "      <td>This handbill was used to advertise the Canton...</td>\n",
       "      <td>04/08/2021</td>\n",
       "      <td>47e60712db3042aebfdf3c4918065a91</td>\n",
       "      <td>1958</td>\n",
       "      <td>National Museum of Singapore</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>C13CCAE3-921C-4C4C-881F-E4AE4591F4F6</td>\n",
       "      <td>Abstract Series</td>\n",
       "      <td>roots_collections</td>\n",
       "      <td>https://www.roots.gov.sg/Collection-Landing/li...</td>\n",
       "      <td>Born in 1934 in Singapore, Chieu Shuey Fook gr...</td>\n",
       "      <td>04/08/2021</td>\n",
       "      <td>c13ccae3921c4c4c881fe4ae4591f4f6</td>\n",
       "      <td>1998</td>\n",
       "      <td>National Gallery Singapore</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>496F5795-5F20-4C9D-B63C-F21E3E187F92</td>\n",
       "      <td>Profile - Girl with ribbon</td>\n",
       "      <td>roots_collections</td>\n",
       "      <td>https://www.roots.gov.sg/Collection-Landing/li...</td>\n",
       "      <td>Tay Boon Pin (b.1936) received training at NAF...</td>\n",
       "      <td>06/08/2021</td>\n",
       "      <td>496f57955f204c9db63cf21e3e187f92</td>\n",
       "      <td>1963</td>\n",
       "      <td>National Gallery Singapore</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>30C350D9-CDA3-41FB-AE7A-220CE268751B</td>\n",
       "      <td>Farmer</td>\n",
       "      <td>roots_collections</td>\n",
       "      <td>https://www.roots.gov.sg/Collection-Landing/li...</td>\n",
       "      <td>Born in Fujian Province, Liu Kang (1911-2004) ...</td>\n",
       "      <td>04/08/2021</td>\n",
       "      <td>30c350d9cda341fbae7a220ce268751b</td>\n",
       "      <td>1987</td>\n",
       "      <td>National Gallery Singapore</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>DF923BAB-1130-4F18-8C0B-C9A428D5151E</td>\n",
       "      <td>Untitled</td>\n",
       "      <td>roots_collections</td>\n",
       "      <td>https://www.roots.gov.sg/Collection-Landing/li...</td>\n",
       "      <td>Tan Teng-Kee was born in Batu Pahat, Johor, Ma...</td>\n",
       "      <td>06/08/2021</td>\n",
       "      <td>df923bab11304f188c0bc9a428d5151e</td>\n",
       "      <td>1977</td>\n",
       "      <td>National Gallery Singapore</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4375</th>\n",
       "      <td>4375</td>\n",
       "      <td>03FBF731-B9AE-44D2-BAC1-2533B34CDDEE</td>\n",
       "      <td>Ceremonial bag</td>\n",
       "      <td>roots_collections</td>\n",
       "      <td>https://www.roots.gov.sg/Collection-Landing/li...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04/08/2021</td>\n",
       "      <td>03fbf731b9ae44d2bac12533b34cddee</td>\n",
       "      <td>Early 20th century</td>\n",
       "      <td>Asian Civilisations Museum</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4376</th>\n",
       "      <td>4376</td>\n",
       "      <td>F3085CA6-B148-4954-98D7-00F9B5C4FE3B</td>\n",
       "      <td>Miniature seal with monkey</td>\n",
       "      <td>roots_collections</td>\n",
       "      <td>https://www.roots.gov.sg/Collection-Landing/li...</td>\n",
       "      <td>This uncut seal has a carved monkey seated on ...</td>\n",
       "      <td>25/01/2022</td>\n",
       "      <td>f3085ca6b148495498d700f9b5c4fe3b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4377</th>\n",
       "      <td>4377</td>\n",
       "      <td>C5342626-5143-4CE4-8A18-FF028442A40B</td>\n",
       "      <td>Ornament</td>\n",
       "      <td>roots_collections</td>\n",
       "      <td>https://www.roots.gov.sg/Collection-Landing/li...</td>\n",
       "      <td>This silver gilt ornament would have been sewn...</td>\n",
       "      <td>04/08/2021</td>\n",
       "      <td>c534262651434ce48a18ff028442a40b</td>\n",
       "      <td>Early 20th century</td>\n",
       "      <td>Asian Civilisations Museum</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4378</th>\n",
       "      <td>4378</td>\n",
       "      <td>38892231-F5E8-4E6F-A53C-53CF8CC3E132</td>\n",
       "      <td>Not titled (Tea vendor)</td>\n",
       "      <td>roots_collections</td>\n",
       "      <td>https://www.roots.gov.sg/Collection-Landing/li...</td>\n",
       "      <td>Nguyen Trung was born in in 1940, in Soc Trang...</td>\n",
       "      <td>06/08/2021</td>\n",
       "      <td>38892231f5e84e6fa53c53cf8cc3e132</td>\n",
       "      <td>1963</td>\n",
       "      <td>National Gallery Singapore</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4379</th>\n",
       "      <td>4379</td>\n",
       "      <td>B43D8709-0104-4EEC-963A-6A5E9760981C</td>\n",
       "      <td>Caucasian Lady in Red Dress</td>\n",
       "      <td>roots_collections</td>\n",
       "      <td>https://www.roots.gov.sg/Collection-Landing/li...</td>\n",
       "      <td>Born in Fujian Province, Liu Kang (1911-2004) ...</td>\n",
       "      <td>04/08/2021</td>\n",
       "      <td>b43d870901044eec963a6a5e9760981c</td>\n",
       "      <td>1961</td>\n",
       "      <td>National Gallery Singapore</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4380 rows × 223 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                        documents_0_id  \\\n",
       "0             0  47E60712-DB30-42AE-BFDF-3C4918065A91   \n",
       "1             1  C13CCAE3-921C-4C4C-881F-E4AE4591F4F6   \n",
       "2             2  496F5795-5F20-4C9D-B63C-F21E3E187F92   \n",
       "3             3  30C350D9-CDA3-41FB-AE7A-220CE268751B   \n",
       "4             4  DF923BAB-1130-4F18-8C0B-C9A428D5151E   \n",
       "...         ...                                   ...   \n",
       "4375       4375  03FBF731-B9AE-44D2-BAC1-2533B34CDDEE   \n",
       "4376       4376  F3085CA6-B148-4954-98D7-00F9B5C4FE3B   \n",
       "4377       4377  C5342626-5143-4CE4-8A18-FF028442A40B   \n",
       "4378       4378  38892231-F5E8-4E6F-A53C-53CF8CC3E132   \n",
       "4379       4379  B43D8709-0104-4EEC-963A-6A5E9760981C   \n",
       "\n",
       "                                      documents_0_title documents_0_source  \\\n",
       "0     Handbill for the Cantonese movie, ‘Peach Bloss...  roots_collections   \n",
       "1                                       Abstract Series  roots_collections   \n",
       "2                            Profile - Girl with ribbon  roots_collections   \n",
       "3                                                Farmer  roots_collections   \n",
       "4                                              Untitled  roots_collections   \n",
       "...                                                 ...                ...   \n",
       "4375                                     Ceremonial bag  roots_collections   \n",
       "4376                         Miniature seal with monkey  roots_collections   \n",
       "4377                                           Ornament  roots_collections   \n",
       "4378                            Not titled (Tea vendor)  roots_collections   \n",
       "4379                        Caucasian Lady in Red Dress  roots_collections   \n",
       "\n",
       "                                       documents_0_path  \\\n",
       "0     https://www.roots.gov.sg/Collection-Landing/li...   \n",
       "1     https://www.roots.gov.sg/Collection-Landing/li...   \n",
       "2     https://www.roots.gov.sg/Collection-Landing/li...   \n",
       "3     https://www.roots.gov.sg/Collection-Landing/li...   \n",
       "4     https://www.roots.gov.sg/Collection-Landing/li...   \n",
       "...                                                 ...   \n",
       "4375  https://www.roots.gov.sg/Collection-Landing/li...   \n",
       "4376  https://www.roots.gov.sg/Collection-Landing/li...   \n",
       "4377  https://www.roots.gov.sg/Collection-Landing/li...   \n",
       "4378  https://www.roots.gov.sg/Collection-Landing/li...   \n",
       "4379  https://www.roots.gov.sg/Collection-Landing/li...   \n",
       "\n",
       "                                    documents_0_content  \\\n",
       "0     This handbill was used to advertise the Canton...   \n",
       "1     Born in 1934 in Singapore, Chieu Shuey Fook gr...   \n",
       "2     Tay Boon Pin (b.1936) received training at NAF...   \n",
       "3     Born in Fujian Province, Liu Kang (1911-2004) ...   \n",
       "4     Tan Teng-Kee was born in Batu Pahat, Johor, Ma...   \n",
       "...                                                 ...   \n",
       "4375                                                NaN   \n",
       "4376  This uncut seal has a carved monkey seated on ...   \n",
       "4377  This silver gilt ornament would have been sewn...   \n",
       "4378  Nguyen Trung was born in in 1940, in Soc Trang...   \n",
       "4379  Born in Fujian Province, Liu Kang (1911-2004) ...   \n",
       "\n",
       "     documents_0_lastModifiedDate    documents_0_metadata_rootsUuid  \\\n",
       "0                      04/08/2021  47e60712db3042aebfdf3c4918065a91   \n",
       "1                      04/08/2021  c13ccae3921c4c4c881fe4ae4591f4f6   \n",
       "2                      06/08/2021  496f57955f204c9db63cf21e3e187f92   \n",
       "3                      04/08/2021  30c350d9cda341fbae7a220ce268751b   \n",
       "4                      06/08/2021  df923bab11304f188c0bc9a428d5151e   \n",
       "...                           ...                               ...   \n",
       "4375                   04/08/2021  03fbf731b9ae44d2bac12533b34cddee   \n",
       "4376                   25/01/2022  f3085ca6b148495498d700f9b5c4fe3b   \n",
       "4377                   04/08/2021  c534262651434ce48a18ff028442a40b   \n",
       "4378                   06/08/2021  38892231f5e84e6fa53c53cf8cc3e132   \n",
       "4379                   04/08/2021  b43d870901044eec963a6a5e9760981c   \n",
       "\n",
       "     documents_0_metadata_date_period documents_0_metadata_collection_of  ...  \\\n",
       "0                                1958       National Museum of Singapore  ...   \n",
       "1                                1998         National Gallery Singapore  ...   \n",
       "2                                1963         National Gallery Singapore  ...   \n",
       "3                                1987         National Gallery Singapore  ...   \n",
       "4                                1977         National Gallery Singapore  ...   \n",
       "...                               ...                                ...  ...   \n",
       "4375               Early 20th century         Asian Civilisations Museum  ...   \n",
       "4376                              NaN                                NaN  ...   \n",
       "4377               Early 20th century         Asian Civilisations Museum  ...   \n",
       "4378                             1963         National Gallery Singapore  ...   \n",
       "4379                             1961         National Gallery Singapore  ...   \n",
       "\n",
       "     documents_0_tags_subject_29 documents_0_tags_subject_30  \\\n",
       "0                            NaN                         NaN   \n",
       "1                            NaN                         NaN   \n",
       "2                            NaN                         NaN   \n",
       "3                            NaN                         NaN   \n",
       "4                            NaN                         NaN   \n",
       "...                          ...                         ...   \n",
       "4375                         NaN                         NaN   \n",
       "4376                         NaN                         NaN   \n",
       "4377                         NaN                         NaN   \n",
       "4378                         NaN                         NaN   \n",
       "4379                         NaN                         NaN   \n",
       "\n",
       "     documents_0_tags_subject_31 documents_0_tags_subject_32  \\\n",
       "0                            NaN                         NaN   \n",
       "1                            NaN                         NaN   \n",
       "2                            NaN                         NaN   \n",
       "3                            NaN                         NaN   \n",
       "4                            NaN                         NaN   \n",
       "...                          ...                         ...   \n",
       "4375                         NaN                         NaN   \n",
       "4376                         NaN                         NaN   \n",
       "4377                         NaN                         NaN   \n",
       "4378                         NaN                         NaN   \n",
       "4379                         NaN                         NaN   \n",
       "\n",
       "     documents_0_tags_subject_33 documents_0_tags_geobuildings_5  \\\n",
       "0                            NaN                             NaN   \n",
       "1                            NaN                             NaN   \n",
       "2                            NaN                             NaN   \n",
       "3                            NaN                             NaN   \n",
       "4                            NaN                             NaN   \n",
       "...                          ...                             ...   \n",
       "4375                         NaN                             NaN   \n",
       "4376                         NaN                             NaN   \n",
       "4377                         NaN                             NaN   \n",
       "4378                         NaN                             NaN   \n",
       "4379                         NaN                             NaN   \n",
       "\n",
       "     documents_0_tags_geobuildings_6 documents_0_tags_geobuildings_7  \\\n",
       "0                                NaN                             NaN   \n",
       "1                                NaN                             NaN   \n",
       "2                                NaN                             NaN   \n",
       "3                                NaN                             NaN   \n",
       "4                                NaN                             NaN   \n",
       "...                              ...                             ...   \n",
       "4375                             NaN                             NaN   \n",
       "4376                             NaN                             NaN   \n",
       "4377                             NaN                             NaN   \n",
       "4378                             NaN                             NaN   \n",
       "4379                             NaN                             NaN   \n",
       "\n",
       "     documents_0_metadata_scale_type documents_0_metadata_material_5  \n",
       "0                                NaN                             NaN  \n",
       "1                                NaN                             NaN  \n",
       "2                                NaN                             NaN  \n",
       "3                                NaN                             NaN  \n",
       "4                                NaN                             NaN  \n",
       "...                              ...                             ...  \n",
       "4375                             NaN                             NaN  \n",
       "4376                             NaN                             NaN  \n",
       "4377                             NaN                             NaN  \n",
       "4378                             NaN                             NaN  \n",
       "4379                             NaN                             NaN  \n",
       "\n",
       "[4380 rows x 223 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e078681",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T07:12:42.539298Z",
     "start_time": "2023-02-14T07:12:42.468215Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800421"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6792ffc7",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-02-14T07:12:47.246Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4827fb365f934955ab422e1f4d2f81d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48dc7787ccb94f10a0fb6c0cab0e5cc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas_profiling\n",
    "df.profile_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fbba4260",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T04:43:13.966274Z",
     "start_time": "2023-02-14T04:43:13.898574Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                         0.000000\n",
       "documents_0_id                     0.001826\n",
       "documents_0_title                  0.001826\n",
       "documents_0_source                 0.001826\n",
       "documents_0_path                   0.001826\n",
       "                                     ...   \n",
       "documents_0_tags_geobuildings_5    0.999543\n",
       "documents_0_tags_geobuildings_6    0.999543\n",
       "documents_0_tags_geobuildings_7    0.999543\n",
       "documents_0_metadata_scale_type    0.999772\n",
       "documents_0_metadata_material_5    0.999772\n",
       "Length: 223, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "538bddc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T04:45:00.078578Z",
     "start_time": "2023-02-14T04:45:00.074658Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4785388127853881"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['documents_0_metadata_creator'].isna().sum()/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e73a54e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T04:45:36.515610Z",
     "start_time": "2023-02-14T04:45:36.512000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5004566210045662"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['documents_0_tags_person_0'].isna().sum()/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "04b832ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T06:15:37.424999Z",
     "start_time": "2023-02-14T06:15:37.417846Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>documents_0_metadata_creator</th>\n",
       "      <th>documents_0_tags_person_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chieu Shuey Fook</td>\n",
       "      <td>Chieu, Shuey Fook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tay Boon Pin</td>\n",
       "      <td>Tay, Boon Pin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Liu Kang</td>\n",
       "      <td>Liu, Kang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tan Teng Kee</td>\n",
       "      <td>Tan, Teng Kee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4375</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4376</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4377</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4378</th>\n",
       "      <td>Nguyen Trung</td>\n",
       "      <td>Nguyen Trung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4379</th>\n",
       "      <td>Liu Kang</td>\n",
       "      <td>Liu, Kang</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4380 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     documents_0_metadata_creator documents_0_tags_person_0\n",
       "0                             NaN                       NaN\n",
       "1                Chieu Shuey Fook         Chieu, Shuey Fook\n",
       "2                    Tay Boon Pin             Tay, Boon Pin\n",
       "3                        Liu Kang                 Liu, Kang\n",
       "4                    Tan Teng Kee             Tan, Teng Kee\n",
       "...                           ...                       ...\n",
       "4375                          NaN                       NaN\n",
       "4376                          NaN                       NaN\n",
       "4377                          NaN                       NaN\n",
       "4378                 Nguyen Trung              Nguyen Trung\n",
       "4379                     Liu Kang                 Liu, Kang\n",
       "\n",
       "[4380 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['documents_0_metadata_creator', 'documents_0_tags_person_0']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47c4403c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T04:49:04.749361Z",
     "start_time": "2023-02-14T04:49:04.745064Z"
    }
   },
   "outputs": [],
   "source": [
    "df['que'] = df['documents_0_metadata_creator'][(df['documents_0_metadata_creator'] >= df['documents_0_tags_person_0'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b6378892",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T04:49:08.836094Z",
     "start_time": "2023-02-14T04:49:08.832015Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                NaN\n",
       "1                NaN\n",
       "2                NaN\n",
       "3                NaN\n",
       "4                NaN\n",
       "            ...     \n",
       "4375             NaN\n",
       "4376             NaN\n",
       "4377             NaN\n",
       "4378    Nguyen Trung\n",
       "4379             NaN\n",
       "Name: que, Length: 4380, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['que']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0bdecadf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T04:52:56.134306Z",
     "start_time": "2023-02-14T04:52:56.124615Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>self</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chieu Shuey Fook</td>\n",
       "      <td>Chieu, Shuey Fook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tay Boon Pin</td>\n",
       "      <td>Tay, Boon Pin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Liu Kang</td>\n",
       "      <td>Liu, Kang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tan Teng Kee</td>\n",
       "      <td>Tan, Teng Kee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Arthur Yap</td>\n",
       "      <td>Yap, Arthur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4366</th>\n",
       "      <td>Georgette Chen</td>\n",
       "      <td>Chen, Georgette</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4368</th>\n",
       "      <td>Ang Ah Tee</td>\n",
       "      <td>Ang, Ah Tee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4371</th>\n",
       "      <td>Lim Tze Peng</td>\n",
       "      <td>Lim, Tze Peng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4374</th>\n",
       "      <td>Ang Ah Tee</td>\n",
       "      <td>Ang, Ah Tee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4379</th>\n",
       "      <td>Liu Kang</td>\n",
       "      <td>Liu, Kang</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1647 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  self              other\n",
       "1     Chieu Shuey Fook  Chieu, Shuey Fook\n",
       "2         Tay Boon Pin      Tay, Boon Pin\n",
       "3             Liu Kang          Liu, Kang\n",
       "4         Tan Teng Kee      Tan, Teng Kee\n",
       "5           Arthur Yap        Yap, Arthur\n",
       "...                ...                ...\n",
       "4366    Georgette Chen    Chen, Georgette\n",
       "4368        Ang Ah Tee        Ang, Ah Tee\n",
       "4371      Lim Tze Peng      Lim, Tze Peng\n",
       "4374        Ang Ah Tee        Ang, Ah Tee\n",
       "4379          Liu Kang          Liu, Kang\n",
       "\n",
       "[1647 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['documents_0_metadata_creator'].compare(df['documents_0_tags_person_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2a77bdb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T04:54:56.905923Z",
     "start_time": "2023-02-14T04:54:56.902106Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7111872146118722"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['documents_0_tags_organisation_0'].isna().sum()/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7f9b0ff5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T04:58:11.731617Z",
     "start_time": "2023-02-14T04:58:11.726933Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2636986301369863"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['documents_0_content'].isna().sum()/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6a4e55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
